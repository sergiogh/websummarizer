URL,Summary,Image_URL
https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1,"The technology guide offers a comprehensive walkthrough on developing a RAG-based (Retrieval Augmented Generation) Large Language Model (LLM) application, progressively scaled on distributed computing. Authored by Goku Mohandas and Philipp Moritz, the guide aims to build an application that augments Python's Ray ML framework with external data sources to improve overall data management and serviceability.

By using technical tools such as OpenAI, Llama, and Anyscale Endpoints for optimization, the guide undertakes the significant task of handling large data sets, compute-intensive workloads, and other performance parameters. A considerable part of the tutorial is dedicated to evaluating different application configurations for achieving quality responses and optimized performance.

The Ray ML framework's documentation is chosen as a data source for experimenting with the embedding model, chunking logic, and LLM. They underscored that scale from the start is a crucial aspect of LLM applications due to the handling of large datasets and serving requirements. Scaling and serving the LLM application in production remains in focus.

Despite the complex and highly technical nature of the guide with multiple moving parts involved, it promised to break down the evaluation processes and share findings towards achieving an optimized configuration.
",https://images.ctfassets.net/xjan103pcp94/3TBU5BOctjuaPyxuA8PGul/1c1b0b0129be5fef9eaef73063491582/image1.png
https://insights.daffodilsw.com/blog/google-gemini-algorithm-the-next-level-ai-model,"Google's research lab, DeepMind, plans to launch a novel artificial intelligence (AI) model dubbed the Gemini AI. Unveiled along the Google Pixel products during Google I/O event, Gemini AI seeks to surpass OpenAI's GPT-4 leveraging reinforcement learning. DeepMind's CEO, Demis Hassabis, forecasts Gemini's development cost in the hundreds of millions realm, marking Google's hefty investment in the AI project. Due to incorporate problem-solving and strategic planning components from the celebrated AlphaGo program, Gemini is anticipated to replace Google's existing AI model, PaLM 2, underpinning several services like the Duet AI in Workspace apps and Bard chatbot. Enhanced performance, strategic decision support, dynamic context understanding, continuous self-improvement, and simulated environment interactions feature among Gemini's expected capabilities. Google's preparations to launch Gemini come against the backdrop of a competitive generative AI environment.",https://insights.daffodilsw.com/hs-fs/hubfs/Kartik/blog%20header%20image.png.jpg?width=1800&name=blog%20header%20image.png.jpg
https://arxiv.org/abs/2307.06627v1,"In a recent paper submitted on 13 July 2023, Qian Zuo and Tongyang Li proposed fast and practical quantum-inspired classical algorithms for solving linear systems. The researchers present methods that can construct a solution for a given matrix and vector, with spectral norm constraints. Notably, their algorithms show a polynomial speedup in condition numbers compared to the previous best results by Shao and Montanaro. The algorithms also match the quantum lower bound for sparse matrices, complemented by efficiencies in certain specific conditions. The researchers also demonstrated two new techniques using the heavy ball momentum method, facilitating significant speedups. Experimental results with synthetic and real-world datasets support the theoretical claims.",
https://www.nber.org/papers/w31326,"Jesús Fernández-Villaverde and Isaiah J. Hull have introduced a novel method of solving dynamic programming problems using a quantum annealer - a device dedicated to combinatorial optimization. The unique approach optimizes solving the Real Business Cycle Model, achieving an order-of-magnitude speedup over existing benchmarks. Quantum annealers solve NP-hard problems by generating global solutions in milliseconds regardless of problem size. During this project, Hull was involved with CogniFrame Inc., in partnership with D-Wave Systems - the creators of the quantum annealers used in the research. Notably, D-Wave didn't provide support or compute time for the project. These results could have potential applications for tackling more complex economic problems.",https://www.nber.org/sites/default/files/styles/promo/public/2023-07/Darghi-MFL-Cover-slide.jpg?itok=Vdnd6Eyd
https://scirate.com/arxiv/2305.13362,"In a recent study, a team of researchers including Amira Abbas, Robbie King, Hsin-Yuan Huang, William J. Huggins, Ramis Movassagh, Dar Gilboa, and Jarrod R. McClean investigated the efficiency of training in parameterized quantum models compared to classical neural networks. They discovered that achieving quantum backpropagation scaling, analogous to classical neural networks, is not possible without access to multiple copies of a state. A subsequent algorithm was introduced, based on shadow tomography, that matches backpropagation scaling in quantum resources and minimizes classical auxiliary computational costs. However, the study revealed that reusing quantum information for practical purposes has intricate nuances and elucidated unique challenges in training large quantum models, indicating a potential shift in the trajectory of quantum machine learning. The research was submitted on 22 May 2023 and published on 24 May 2023.
",
https://research.ibm.com/blog/qiskit-summer-school-2023,"IBM Quantum has announced the Qiskit Global Summer School 2023, a virtual event that expects to draw 5,000 participants to learn about quantum computing. The event departs from previous formats focusing on advanced topics, opting for a ""back-to-basics"" approach to increase accessibility for newcomers. The core of the program comprises pre-recorded lectures and labs to provide both theoretical understanding and hands-on experience with quantum hardware. Instructors Olivia Lanes and John Watrous will be among those conducting lectures and interactive live-Q&A sessions. Participants will also benefit from a Discord server for networking, project collaborations and problem solving.
",
https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/quantum-technology-sees-record-investments-progress-on-talent-gap,"Quantum technology investment set a record in 2022, with startups receiving $2.35 billion, a slight increase compared to 2021 according to the 2023 Quantum Technology Monitor conducted by McKinsey. The report also highlighted that the four industries most likely to benefit from quantum computing - automotive, chemicals, financial services, and life sciences - could gain up to $1.3 trillion by 2035. Last year also witnessed technical advancements in quantum tech, including the award of the Nobel Prize in Physics for research in quantum entanglement and companies foreseeing quantum processors with thousands of qubits by 2025. The gap regarding the scarce expertise in quantum technologies is starting to decrease due to the initiatives taken by universities to offer master's programs in quantum technologies. However, there was a decline in new quantum technology start-ups, as only 19 were established compared to 41 in 2021, suggesting investors' preference for established start-ups. The largest national quantum technology investment was made by China at $15.3 billion. Developments happened on the patent front as well, although at a slower pace, with 1,589 patents granted in 2022, a 61% decrease from 2021.",
